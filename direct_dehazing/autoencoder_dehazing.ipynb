{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6a40e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from data import get_dataloaders\n",
    "from model import Dehazer\n",
    "from loss import HybridLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b04ff36",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "random.seed(43)\n",
    "torch.manual_seed(43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1489dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# options: [\"ohaze\", \"dh/Middlebury\", \"dh/NYU\"]\n",
    "DATASET = \"ohaze\"\n",
    "BATCH_SIZE = 8\n",
    "TRAIN_SPLIT = 0.8\n",
    "train_loader, test_loader = get_dataloaders(DATASET, TRAIN_SPLIT, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4705ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f28aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Define the hybrid loss \"\"\"\n",
    "\n",
    "# VGG for perceptual loss\n",
    "vgg_model = models.vgg16(weights=\"VGG16_Weights.DEFAULT\").features\n",
    "feat_extractor = nn.Sequential(*list(vgg_model.children())[:24])  # from relu4_2 layer\n",
    "feat_extractor.add_module(\"avgpool\",nn.AdaptiveAvgPool2d((1, 1)))\n",
    "\n",
    "# ResNet for perceptual loss\n",
    "# resnet = models.resnet18(weights=\"VGG16_Weights.DEFAULT\")\n",
    "# feat_extractor = nn.Sequential(*list(resnet.children())[:7])\n",
    "# feat_extractor.add_module(\"avgpool\",nn.AdaptiveAvgPool2d((1, 1)))\n",
    "\n",
    "num_params_f = sum(torch.numel(p) for p in feat_extractor.parameters())\n",
    "print(f\"Number of parameters in the feature extractor: {num_params_f}\")\n",
    "\n",
    "# Loss\n",
    "GAMMA = 1.5\n",
    "feat_extractor.to(device)\n",
    "criterion = HybridLoss(feat_extractor, gamma=GAMMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11e79f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the model\n",
    "model = Dehazer()\n",
    "num_params_m = sum(torch.numel(p) for p in model.parameters())\n",
    "print(f\"Number of parameters in the model: {num_params_m}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bcaf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90efa409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, writer, epoch):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, targets in test_loader:\n",
    "            images = images.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "\n",
    "            # Convert the outputs and targets to numpy arrays\n",
    "            outputs_np = outputs.cpu().numpy()\n",
    "            targets_np = targets.numpy()\n",
    "\n",
    "            num_outs = outputs.shape[0]\n",
    "            fig, axs = plt.subplots(2, num_outs, figsize=(20, 8))\n",
    "\n",
    "            for i in range(num_outs):\n",
    "\n",
    "                # get channel-wise max\n",
    "                maxes = []\n",
    "                for c in range(3):\n",
    "                    maxes.append(outputs_np[i][c].max())\n",
    "                maxes = np.array(maxes)\n",
    "\n",
    "                # normalize using max values\n",
    "                for c in range(3):\n",
    "                    outputs_np[i][c] /= maxes[c]\n",
    "                outputs_np[i] *= 255\n",
    "\n",
    "                output = outputs_np[i].astype(\"uint8\")\n",
    "\n",
    "                # Plot ground truth image in the first row\n",
    "                axs[0, i].imshow(targets_np[i].transpose(1, 2, 0))\n",
    "                axs[0, i].set_title(\"Ground Truth\")\n",
    "                axs[0, i].axis(\"off\")\n",
    "\n",
    "                # Plot predicted image in the second row\n",
    "                axs[1, i].imshow((output).transpose(1, 2, 0))\n",
    "                axs[1, i].set_title(\"Output\")\n",
    "                axs[1, i].axis(\"off\")\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'plot_{epoch}.png')\n",
    "\n",
    "            # Load the image file as a tensor\n",
    "            image = torch.from_numpy(np.array(Image.open('plot.png'))).permute(2, 0, 1).float() / 255\n",
    "\n",
    "            # Add the image to the SummaryWriter\n",
    "            writer.add_image('Plot', image)\n",
    "            plt.show()\n",
    "            break\n",
    "\n",
    "    writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a70276d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, test_loader, num_epochs):\n",
    "    model.to(device)\n",
    "\n",
    "    log_dir = f\"./logs/{DATASET}/lr{learning_rate}_gamma{GAMMA}_epochs{num_epochs}\"\n",
    "    writer = SummaryWriter(log_dir)\n",
    "    weights_dir = os.path.join(log_dir, \"weights\")\n",
    "    os.makedirs(weights_dir, exist_ok=True)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "            running_loss = 0.0\n",
    "            for idx, (images, targets) in enumerate(train_loader):\n",
    "                images = images.to(device)\n",
    "                targets = targets.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(images)\n",
    "\n",
    "                # Compute the loss\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "                # Backward and optimize\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "\n",
    "            epoch_loss = running_loss / len(train_loader)\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.6f}\")\n",
    "\n",
    "            if (epoch+1)%3 == 0:\n",
    "                test(model, test_loader, writer, epoch)\n",
    "                model.train()\n",
    "                checkpoint = {\n",
    "                        'epoch' : epoch + 1,\n",
    "                        'state_dict': model.state_dict(),\n",
    "                        'optimizer': optimizer.state_dict()\n",
    "                    }\n",
    "                torch.save(checkpoint, os.path.join(weights_dir, f\"{(epoch+1):03}.pth\"))\n",
    "\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6fc6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS=30\n",
    "train(model, train_loader, test_loader, NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdc93e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
