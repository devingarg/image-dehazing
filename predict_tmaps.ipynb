{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7dc27deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5015833",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dehazer(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=3):\n",
    "        super(Dehazer, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv2d(512, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "            nn.Conv2d(256, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "            nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "            nn.Conv2d(64, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c6d0c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the checkpoint\n",
    "CKPT_PATH = \"weights/lr_0.0002_dhaze_epochs50_test_run/checkpoint_epoch_50.pth\"\n",
    "checkpoint = torch.load(CKPT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9f61f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Dehazer(in_channels=3, out_channels=1)\n",
    "model.load_state_dict(checkpoint[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8bc97b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_files(src_dir, src_file_list):\n",
    "    \n",
    "    fnames = []\n",
    "    if src_file_list is None:\n",
    "        # no file containing the list, so list all files in the dir\n",
    "        for f in os.listdir(src_dir):\n",
    "            fnames.append(os.path.join(src_dir, f))\n",
    "        \n",
    "    else:\n",
    "        # open the file\n",
    "        with open(src_file_list, \"r\") as f:\n",
    "            for line in f.readlines():\n",
    "                fnames.append(line.strip())\n",
    "    \n",
    "    return fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b38a9a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_source(src_dir, dst_dir, factor=2):\n",
    "\n",
    "    for filename in tqdm(os.listdir(src_dir)):\n",
    "        \n",
    "        src_path = os.path.join(src_dir, filename)\n",
    "\n",
    "        if os.path.isfile(src_path):\n",
    "            \n",
    "            image = Image.open(src_path)\n",
    "            \n",
    "            width, height = image.size\n",
    "\n",
    "            new_width = width // factor\n",
    "            new_height = height // factor\n",
    "\n",
    "            resized_image = image.resize((new_width, new_height))\n",
    "\n",
    "            # Construct the destination file path\n",
    "            dst_path = os.path.join(dst_dir, filename)\n",
    "\n",
    "            # Save the resized image to the destination directory\n",
    "            resized_image.save(dst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c682b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_dir = \"dhazy/NYU_Hazy\"\n",
    "src_file_list = None\n",
    "# src_file_list = \"dhazy/NYU_split/test_Hazy.txt\"\n",
    "\n",
    "dst_dir = \"dhazy/NYU_predictedDepthMap\"\n",
    "os.makedirs(dst_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb6b0f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_src = \"dhazy/Middlebury_Hazy_reshaped\"\n",
    "os.makedirs(reshaped_src, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "186f8e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:01<00:00, 12.39it/s]\n"
     ]
    }
   ],
   "source": [
    "reshape_source(src_dir, reshaped_src, factor=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c6df618",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "#     transforms.Resize(400),\n",
    "#     transforms.CenterCrop(400),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])          \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9b536ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = collect_files(src_dir, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f027272",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1449/1449 [00:46<00:00, 31.43it/s]\n"
     ]
    }
   ],
   "source": [
    "# get predictions\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "model.to(device)\n",
    "\n",
    "for f in tqdm(files):\n",
    "\n",
    "    # read in the image\n",
    "    hazy_img = transform(Image.open(f)).unsqueeze(0)\n",
    "    \n",
    "    # get the result\n",
    "    output = model(hazy_img.to(device)).detach().cpu().numpy().squeeze()\n",
    "    output = output/output.max()\n",
    "    output = output*255\n",
    "    output = output.astype(\"uint8\")\n",
    "\n",
    "    # store the result\n",
    "    pil_output = Image.fromarray(output)\n",
    "    dst_fname = os.path.join(dst_dir, os.path.split(f)[1].replace(\"Hazy\", \"predDMap\"))\n",
    "    pil_output.save(dst_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ff0d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
